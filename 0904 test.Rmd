---
title: "0904 test"
author: "Angelina Sun 305739059"
date: "`r Sys.Date()`"
output: html_document
---

# Setting up

```{r}
# load packages
# need to add install.packages?
library(tidymodels)
library(xgboost)
library(dials)
library(recipes)
library(stacks)
library(readr)
library(bonsai)
library(lightgbm)
library(kknn)
library(kernlab)

# load train set
train <- read_csv('train.csv', show_col_types = FALSE) %>%
  select(-name)
test <- read_csv("test.csv", show_col_types = FALSE)

# create 5-fold cross validation
set.seed(42)
train_folds <- vfold_cv(train, v = 10)
```

# Model recipes

```{r}
baseline_recipe <- recipe(percent_dem ~ ., data = train) %>%
  step_mutate(x2013_code = as.factor(x2013_code)) %>%
  step_dummy(x2013_code, one_hot = TRUE) %>%
  step_mutate(voting_perc = total_votes / x0087e, 
              total_population = x0001e, 
              median_age = x0018e,
              male_female_ratio = x0002e / x0003e, 
              age_under_5_perc = x0005e / x0001e, age_5_to_9_perc = x0006e / x0001e, 
              age_10_to_14_perc = x0007e / x0001e, age_15_to_19_perc = x0008e / x0001e, 
              age_20_to_24_perc = x0009e / x0001e, age_25_to_34_perc = x0010e / x0001e, 
              age_35_to_44_perc = x0011e / x0001e, age_45_to_54_perc = x0012e / x0001e, 
              age_55_to_59_perc = x0013e / x0001e, age_60_to_64_perc = x0014e / x0001e, 
              age_65_to_74_perc = x0015e / x0001e, age_75_to_84_perc = x0016e / x0001e, 
              age_over_85_perc = x0017e / x0001e, 
              under_18_perc = x0019e / x0001e, 
              age_18_to_34_perc = (x0021e - (x0009e + x0010e + x0011e + x0012e + x0013e + x0014e + x0015e + x0016e + x0017e) + x0009e + x0010e) / x0001e, 
              white_perc = x0037e / x0001e, black_perc = x0038e,
              ai_cherokee_perc = x0040e / x0001e, ai_chippewa_perc = x0041e / x0001e,
              ai_navajo_perc = x0042e / x0001e, ai_sioux_perc = x0043e / x0001e, 
              a_chinese_perc = x0046e / x0001e, a_filipino_perc = x0047e / x0001e, 
              a_japanese_perc = x0048e / x0001e, a_korean_perc = x0049e / x0001e, 
              a_vietnamese_perc = x0050e / x0001e, a_other_perc = x0051e / x0001e, 
              nh_hawaiian_perc = x0053e / x0001e, nh_chamorro_perc = x0054e / x0001e,
              nh_samoan_perc = x0055e / x0001e, nh_other_perc = x0056e / x0001e,
              one_race_other_perc = x0057e / x0001e, 
              white_black_perc = x0059e / x0001e, white_indian_perc = x0060e / x0001e,
              white_asian_perc = x0061e / x0001e, black_indian_perc = x0062e / x0001e,
              total_white_perc = x0064e / x0001e, total_black_perc = x0065e / x0001e,
              total_indian_perc = x0066e / x0001e, total_asian_perc = x0067e / x0001e,
              total_hawaiian_perc = x0068e / x0001e, total_other_perc = x0069e / x0001e,
              total_hispanic_perc = x0071e / x0001e, 
              
              diversity_index = -(total_white_perc   * log(total_white_perc, base = exp(1))
                                  + total_black_perc  * log(total_black_perc, base = exp(1))
                                  + total_indian_perc  * log(total_indian_perc, base = exp(1))
                                  + total_asian_perc  * log(total_asian_perc, base = exp(1))
                                  + total_hawaiian_perc  * log(total_hawaiian_perc, base = exp(1))
                                  + total_other_perc  * log(total_other_perc, base = exp(1))
                                  ),
              his_mexican_perc = x0072e / x0001e, his_puerto_rican_perc = x0073e / x0001e,
              his_cuban_perc = x0074e / x0001e, his_other_perc = x0075e / x0001e, 
              his_mexican_perc = x0072e / x0001e, 
              
              not_his_white = x0077e / x0001e, not_his_black = x0078e / x0001e, 
              not_his_indian = x0079e / x0001e, not_his_asian = x0080e / x0001e, 
              not_his_hawaiian = x0081e / x0001e, not_his_other = x0082e / x0001e, 
              not_his_two_race_include = x0084e / x0001e, not_his_two_race_exclude = x0085e / x0001e, 
              citizen_over_18_male_female_ratio = x0088e / x0089e, 
              citizen_over_18_perc = x0087e / (x0001e),
              ratio_high_school_18_24 = c01_003e / c01_001e,
              total_housing_units = x0086e, 
              edu_no_hs_perc = (c01_002e + c01_007e + c01_008e) / x0001e, 
              edu_hs_perc = (c01_003e + c01_009e + c01_010e) / x0001e, 
              edu_associate_perc = (c01_004e + c01_011e) / x0001e,
              edu_bachelor_perc = (c01_005e + c01_015e) / x0001e, 
              edu_no_hs_18_to_24_perc = c01_002e / x0001e, 
              edu_hs_18_to_24_perc = c01_003e / x0001e,
              edu_associate_18_to_24_perc = c01_004e / x0001e,
              edu_bachelor_18_to_24_perc = c01_005e / x0001e,
              edu_less_9_over_25_perc = c01_007e / x0001e,
              edu_no_hs_over_25_perc = c01_008e / x0001e,
              edu_hs_over_25_perc = c01_009e / x0001e,
              edu_no_college_over_25_perc = c01_010e / x0001e,
              edu_associate_over_25_perc = c01_011e / x0001e,
              edu_bachelor_over_25_perc = c01_012e / x0001e,
              edu_graduate_over_25_perc = c01_013e / x0001e,
              edu_no_hs_25_to_34_perc = (c01_016e - c01_017e - c01_018e) / x0001e,
              edu_hs_25_to_34_perc = (c01_017e - c01_018e) / x0001e, 
              edu_bachelor_25_to_34_perc = c01_018e / x0001e, 
              edu_no_hs_35_to_44_perc = (c01_019e - c01_020e - c01_021e) / x0001e,
              edu_hs_35_to_44_perc = (c01_020e - c01_021e) / x0001e, 
              edu_bachelor_35_to_44_perc = c01_021e / x0001e, 
              edu_no_hs_45_to_64_perc = (c01_022e - c01_023e - c01_024e) / x0001e,
              edu_hs_45_to_64_perc = (c01_023e - c01_024e) / x0001e, 
              edu_bachelor_45_to_64_perc = c01_024e / x0001e, 
              edu_no_hs_over_65_perc = (c01_025e - c01_026e - c01_027e) / x0001e,
              edu_hs_over_65_perc = (c01_026e - c01_027e) / x0001e, 
              edu_bachelor_over_65_perc = c01_027e / x0001e, 
              
              housing_to_population_ratio = x0086e / x0001e, 
              growth_rate_income = (income_per_cap_2020 - income_per_cap_2016) / income_per_cap_2016, 
              growth_rate_gdp = (gdp_2020 - gdp_2016) / gdp_2016, 
              income_growth_16_17 = (income_per_cap_2017 - income_per_cap_2016) / income_per_cap_2016, 
              income_growth_17_18 = (income_per_cap_2018 - income_per_cap_2017) / income_per_cap_2017, 
              income_growth_18_19 = (income_per_cap_2019 - income_per_cap_2018) / income_per_cap_2018, 
              income_growth_19_20 = (income_per_cap_2020 - income_per_cap_2019) / income_per_cap_2019, 
              gdp_growth_16_17 = (gdp_2017 - gdp_2016) / gdp_2016, 
              gdp_growth_17_18 = (gdp_2018 - gdp_2017) / gdp_2017, 
              gdp_growth_18_19 = (gdp_2019 - gdp_2018) / gdp_2018, 
              gdp_growth_19_20 = (gdp_2020 - gdp_2019) / gdp_2019, 
              income_to_gdp_ratio_16 = income_per_cap_2016 / gdp_2016, 
              income_to_gdp_ratio_17 = income_per_cap_2017 / gdp_2017,
              income_to_gdp_ratio_18 = income_per_cap_2018 / gdp_2018,
              income_to_gdp_ratio_19 = income_per_cap_2019 / gdp_2019,
              income_to_gdp_ratio_20 = income_per_cap_2020 / gdp_2020,
              income_per_housing_16 = income_per_cap_2016 / x0086e, 
              income_per_housing_17 = income_per_cap_2017 / x0086e,
              income_per_housing_18 = income_per_cap_2018 / x0086e,
              income_per_housing_19 = income_per_cap_2019 / x0086e,
              income_per_housing_20 = income_per_cap_2020 / x0086e,
              gdp_per_housing_16 = gdp_2016 / x0086e, 
              gdp_per_housing_17 = gdp_2017 / x0086e,
              gdp_per_housing_18 = gdp_2018 / x0086e,
              gdp_per_housing_19 = gdp_2019 / x0086e,
              gdp_per_housing_20 = gdp_2020 / x0086e

              ) %>%
  step_impute_median(all_predictors()) %>% 
  step_rm(id, c(x0001e:c01_027e))

scaled_recipe = baseline_recipe %>% 
  step_normalize(all_numeric(), -all_outcomes())

prep_rec <- prep(baseline_recipe)
juice(prep_rec)


# baseline recipe containing 41 features 
recipe_41 <- 
  recipe(percent_dem ~., data = train) %>%
  step_mutate(
    per_white = (x0037e / x0001e),
    total_white_perc = x0064e / x0001e,
    edu_bachelor_perc = (c01_005e + c01_015e) / x0001e,
    total_asian_perc = x0067e / x0001e,
    per_latina = (x0071e / x0001e) ,
    edu_bachelor_25_to_34_perc = c01_018e / x0001e,
    edu_bachelor_45_to_64_perc = c01_024e / x0001e, 
    pct_bach_higher_65 = c01_027e / c01_025e,
    total_black_perc = x0065e / x0001e,
    per_asia = (x0044e / x0001e) ,
    edu_associate_perc = (c01_004e + c01_011e) / x0001e,
    income_growth_19_20 = (income_per_cap_2020 - income_per_cap_2019) / income_per_cap_2019, 
    citizen_over_18_male_perc = x0088e / x0025e, 
    pct_hs_higher_65 = c01_026e / c01_025e,
    a_chinese_perc = x0046e / x0001e,
    age_10_to_14_perc = x0007e / x0001e,
    per_other = (x0057e / x0001e) ,
    gdp_growth_19_20 = (gdp_2020 - gdp_2019) / gdp_2019,
    age_5_to_9_perc = x0006e / x0001e, 
    ai_chippewa_perc = x0041e / x0001e,
    pct_college_25 = c01_010e / c01_006e,
    a_korean_perc = x0049e / x0001e, 
    a_other_perc = x0051e / x0001e, 
    growth_rate_gdp = (gdp_2020 - gdp_2016) / gdp_2016,
    white_black_perc = x0059e / x0001e,
    total_indian_perc = x0066e / x0001e,
    ai_cherokee_perc = x0040e / x0001e,
    a_filipino_perc = x0047e / x0001e, 
    per_native = (x0039e / x0001e) , 
    total_other_perc = x0069e / x0001e,
    pct_high_grad_25 = c01_009e / c01_006e,
    black_perc = x0038e / x0001e,
    his_mexican_perc = x0072e / x0001e,
    white_asian_perc = x0061e / x0001e,
    age_45_to_54_perc = x0012e / x0001e, 
    age_60_to_64_perc = x0014e / x0001e,
    his_puerto_rican_perc = x0073e / x0001e,
    housing_to_population_ratio = x0086e / x0001e) %>%
  step_rm(id,x0001e,x0002e, x0003e, x0005e, x0006e, x0007e, x0008e, x0009e, x0010e, x0011e, 
          x0012e, x0013e, x0014e, x0015e, x0016e, x0017e,x0018e, x0019e, x0020e, x0021e, 
          x0022e, x0023e, x0024e, x0025e, x0026e, x0027e, x0029e, x0030e, x0031e, 
          x0033e, x0034e, x0035e, x0036e, x0037e, x0038e, x0039e, x0040e, x0041e,
          x0042e, x0043e, x0044e, x0045e, x0046e, x0047e, x0048e, x0049e, x0050e, 
          x0051e, x0052e, x0053e, x0054e, x0055e, x0056e, x0057e, x0058e, x0059e,
          x0060e, x0061e, x0062e, x0064e, x0065e, x0066e, x0067e, x0068e, x0069e, 
          x0071e, x0072e, x0073e, x0074e, x0075e, x0076e, x0077e, x0078e, x0079e, 
          x0080e, x0081e, x0082e, x0083e, x0084e, x0085e, x0086e, x0087e, x0088e, x0089e, 
          c01_001e, c01_002e, c01_003e, c01_004e, c01_005e, c01_006e, c01_007e, 
          c01_008e, c01_009e, c01_010e, c01_011e, c01_012e, c01_013e, c01_014e, 
          c01_015e, c01_016e, c01_017e, c01_018e, c01_019e, c01_020e, c01_021e, 
          c01_022e, c01_023e, c01_024e, c01_025e, c01_026e, c01_027e, income_per_cap_2016,
          income_per_cap_2017, income_per_cap_2018, income_per_cap_2019,income_per_cap_2020,
          gdp_2017, gdp_2018,gdp_2019, x2013_code) %>%
  step_impute_median(all_predictors())%>%
  step_lincomb(all_predictors())

scaled_recipe_41 = recipe_41 %>% step_normalize(all_numeric(), -all_outcomes())

```

```{r}
# XGBoost specification
xgb_spec <- boost_tree(
  trees = tune(),
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune()
) %>% 
  set_engine("xgboost", objective = "reg:squarederror") %>%
  set_mode("regression")

# XGBoost workflow
xgb_wf <- workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(xgb_spec)

# Register parallel backend
doParallel::registerDoParallel(cores = 7)

# Define parameter space
param_space <- parameters(
  trees(),
  min_n(),
  tree_depth(),
  learn_rate(),
  loss_reduction()
)

# Set seed for reproducibility
set.seed(123)

# Bayesian optimization
tune_res <- tune_bayes(
  xgb_wf,
  resamples = train_folds,
  initial = 10,
  iter = 80,
  param_info = param_space,
  metrics = metric_set(rmse, rsq),
  control = control_bayes(verbose = TRUE, save_pred = TRUE, verbose_iter = TRUE)
)
```


# Tuned models

```{r}
# xgboost with all predictors:
xgb_spec <- boost_tree(
  trees = tune(),
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune()
) %>% 
  set_engine("xgboost", objective = "reg:squarederror") %>%
  set_mode("regression")
# XGBoost workflow
xgb_wf <- workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(xgb_spec)

# random forests with all predictors: 6.688
rf_spec <- 
  rand_forest(mtry = 82, trees = 523, min_n = 2) %>%
  set_engine("ranger", num.threads = 7, importance = "impurity") %>%
  set_mode("regression")
rf_wf <- 
  workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(rf_spec)

# random forests with 41 predictors: 6.866
rf_spec_41 <- 
  rand_forest(mtry = 40, trees = 988, min_n = 3) %>%
  set_engine("ranger", num.threads = 7, importance = "impurity") %>%
  set_mode("regression")
rf_wf_41 <- 
  workflow() %>% 
  add_recipe(scaled_recipe_41) %>%
  add_model(rf_spec_41)


# knn with all predictors: 7.773
knn_spec <- 
  nearest_neighbor(neighbors = 14) %>%
  set_engine("kknn") %>%
  set_mode("regression")
knn_wf <- 
  workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(knn_spec)

# knn with 41 predictors: 7.381
knn_spec_41 <- 
  nearest_neighbor(neighbors = 14) %>%
  set_engine("kknn") %>%
  set_mode("regression")
knn_wf_41 <- 
  workflow() %>% 
  add_recipe(scaled_recipe_41) %>%
  add_model(knn_spec_41)


# lightGBM with all predictors: 6.10
lightgbm_spec <- 
  boost_tree(trees = 1691, min_n = 13,tree_depth = 13) %>%
  set_engine("lightgbm") %>%
  set_mode("regression")
lightgbm_wf <- workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(lightgbm_spec)

# lightGBM with 41 predictors: 6.249
lightgbm_spec_41 <- 
  boost_tree(trees = 1735, min_n = 8,tree_depth = 15) %>%
  set_engine("lightgbm") %>%
  set_mode("regression")
lightgbm_wf_41 <- workflow() %>% 
  add_recipe(scaled_recipe_41) %>%
  add_model(lightgbm_spec_41)


# elastic net with all predictors: 7.75
enet_spec <- 
  linear_reg(penalty = 0.01, mixture = 0.9) %>% 
  set_engine("glmnet") %>%
  set_mode("regression")
enet_wf <- 
  workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(enet_spec)

# elastic net with 41 predictors: 8.424
enet_spec_41 <- 
  linear_reg(penalty = 0.0324, mixture = 0.997) %>% 
  set_engine("glmnet") %>%
  set_mode("regression")
enet_wf_41 <- 
  workflow() %>% 
  add_recipe(scaled_recipe_41) %>%
  add_model(enet_spec_41)


# SVM with all predictors: 6.29
svm_spec <- 
  svm_rbf(cost = 10.9, rbf_sigma = 0.00164) %>%
  set_engine("kernlab") %>%
  set_mode("regression")
svm_wf <- 
  workflow() %>% 
  add_recipe(scaled_recipe) %>%
  add_model(svm_spec)

# SVM with 41 predictors: 6.675
svm_spec_41 <- 
  svm_rbf(cost = 6.53, rbf_sigma = 0.0103) %>%
  set_engine("kernlab") %>%
  set_mode("regression")
svm_wf_41 <- 
  workflow() %>% 
  add_recipe(scaled_recipe_41) %>%
  add_model(svm_spec_41)
```

# Workflow set

```{r}
final_wf_set <- as_workflow_set(xgb_v1_no_l12 = xgb_wf_v1_no_l12, 
                                xgb_v1_with_l12 = xgb_wf_v1_with_l12,
                                xgb_v2 = xgb_wf_v2, 
                                xgb_v3 = xgb_wf_v3,
                                xgb_v4 = xgb_wf_v4,
                                glm_v1 = glm_wf_v1,
                                nnet_v3 = nnet_wf_v3, 
                                nnet_v4 = nnet_wf_v4,
                                rf = rf_wf,
                                rf_41 = rf_wf_41,
                                knn = knn_wf,
                                knn_41 = knn_wf_41,
                                lightgbm = lightgbm_wf,
                                lightgbm_41 = lightgmb_wf_41,
                                enet = enet_wf, 
                                enet_41 = enet_wf_41,
                                svm = svm_wf,
                                svm_41 = svm_wf_41) %>% 
  option_add(
    control = control_stack_grid()
  )
final_set_result <- final_wf_set %>% 
  workflow_map('fit_resamples', 
               seed=30, verbose=TRUE, 
               resamples=train_folds)

collect_metrics(final_set_result)
autoplot(final_set_result)
```
```{r}
stacks()
final_set_stacks <- 
  stacks() %>%
  add_candidates(final_set_result) %>%
  blend_predictions() %>%
  fit_members()
autoplot(final_set_stacks)
autoplot(final_set_stacks, type='weight')
autoplot(final_set_stacks, type='members')
```

```{r}
# set 2 has removes 3 xgboost models
final_wf_set_2 <- as_workflow_set(xgb_v3 = xgb_wf_v3,
                                xgb_v4 = xgb_wf_v4,
                                glm_v1 = glm_wf_v1,
                                nnet_v3 = nnet_wf_v3, 
                                nnet_v4 = nnet_wf_v4,
                                rf_v1 = rf_wf_v1, 
                                knn_v1 = knn_wf_v1, 
                                lightgbm_v1 = lightgbm_wf_v1, 
                                en_v1 = en_wf_v1, 
                                svm_v1 = svm_wf_v1) %>% 
  option_add(
    control = control_stack_grid()
  )
final_set_result_2 <- final_wf_set_2 %>% 
  workflow_map('fit_resamples', 
               seed=30, verbose=TRUE, 
               resamples=train_folds)

collect_metrics(final_set_result_2)
autoplot(final_set_result_2)
```
```{r}
stacks()
final_set_stacks_2 <- 
  stacks() %>%
  add_candidates(final_set_result_2) %>%
  blend_predictions() %>%
  fit_members()
autoplot(final_set_stacks_2)
autoplot(final_set_stacks_2, type='weight')
autoplot(final_set_stacks_2, type='members')
```

Make predictions on test data 
```{r}
test <- read_csv("test.csv", show_col_types = FALSE)

test_results <- final_set_stacks_2 %>% 
  predict(new_data = test) %>% 
  bind_cols(test %>% select(id)) %>% 
  select(id, .pred)

test_results <- test_results %>%
  rename(percent_dem = .pred)

write_csv(test_results, 'team_2_results_stacks_v7.csv')
```


